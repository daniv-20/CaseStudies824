{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1\n",
    "### Danielle Vaithilingam\n",
    "**Part 1: Please download Pytorch and one data set from the UCI ML Repository (I recommend Wisconsin Breast Cancer).  Train at least two different architectures (for example, 1 vs. 2 hidden layers) on this data using Pytorch, and show the learning curve (loss function vs. epochs trained).  Describe your architectures and results (two paragraphs are sufficient).**\n",
    "\n",
    "Wisconsin breast cancer dataset:\n",
    "Wolberg,William, Mangasarian,Olvi, Street,Nick, and Street,W.. (1995). Breast Cancer Wisconsin (Diagnostic). UCI Machine Learning Repository. https://doi.org/10.24432/C5DW2B.\n",
    "\n",
    "MLP set up reference: \n",
    "https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xavier_uniform_\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m## plotting\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "## import / set up pytorch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Sampler, random_split\n",
    "from torch.optim import SGD\n",
    "from torch.nn import MSELoss, Sigmoid\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "# pytorch mlp for binary classification\n",
    "from numpy import vstack\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "## plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 17, 'name': 'Breast Cancer Wisconsin (Diagnostic)', 'repository_url': 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic', 'data_url': 'https://archive.ics.uci.edu/static/public/17/data.csv', 'abstract': 'Diagnostic Wisconsin Breast Cancer Database.', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 569, 'num_features': 30, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['Diagnosis'], 'index_col': ['ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1993, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C5DW2B', 'creators': ['William Wolberg', 'Olvi Mangasarian', 'Nick Street', 'W. Street'], 'intro_paper': {'title': 'Nuclear feature extraction for breast tumor diagnosis', 'authors': 'W. Street, W. Wolberg, O. Mangasarian', 'published_in': 'Electronic imaging', 'year': 1993, 'url': 'https://www.semanticscholar.org/paper/53f0fbb425bc14468eb3bf96b2e1d41ba8087f36', 'doi': '10.1117/12.148698'}, 'additional_info': {'summary': 'Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/\\r\\n\\r\\nSeparating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\\r\\n\\r\\nThe actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\\r\\n\\r\\nThis database is also available through the UW CS ftp server:\\r\\nftp ftp.cs.wisc.edu\\r\\ncd math-prog/cpo-dataset/machine-learn/WDBC/', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1) ID number\\r\\n2) Diagnosis (M = malignant, B = benign)\\r\\n3-32)\\r\\n\\r\\nTen real-valued features are computed for each cell nucleus:\\r\\n\\r\\n\\ta) radius (mean of distances from center to points on the perimeter)\\r\\n\\tb) texture (standard deviation of gray-scale values)\\r\\n\\tc) perimeter\\r\\n\\td) area\\r\\n\\te) smoothness (local variation in radius lengths)\\r\\n\\tf) compactness (perimeter^2 / area - 1.0)\\r\\n\\tg) concavity (severity of concave portions of the contour)\\r\\n\\th) concave points (number of concave portions of the contour)\\r\\n\\ti) symmetry \\r\\n\\tj) fractal dimension (\"coastline approximation\" - 1)', 'citation': None}}\n",
      "                  name     role         type demographic description units  \\\n",
      "0                   ID       ID  Categorical        None        None  None   \n",
      "1            Diagnosis   Target  Categorical        None        None  None   \n",
      "2              radius1  Feature   Continuous        None        None  None   \n",
      "3             texture1  Feature   Continuous        None        None  None   \n",
      "4           perimeter1  Feature   Continuous        None        None  None   \n",
      "5                area1  Feature   Continuous        None        None  None   \n",
      "6          smoothness1  Feature   Continuous        None        None  None   \n",
      "7         compactness1  Feature   Continuous        None        None  None   \n",
      "8           concavity1  Feature   Continuous        None        None  None   \n",
      "9      concave_points1  Feature   Continuous        None        None  None   \n",
      "10           symmetry1  Feature   Continuous        None        None  None   \n",
      "11  fractal_dimension1  Feature   Continuous        None        None  None   \n",
      "12             radius2  Feature   Continuous        None        None  None   \n",
      "13            texture2  Feature   Continuous        None        None  None   \n",
      "14          perimeter2  Feature   Continuous        None        None  None   \n",
      "15               area2  Feature   Continuous        None        None  None   \n",
      "16         smoothness2  Feature   Continuous        None        None  None   \n",
      "17        compactness2  Feature   Continuous        None        None  None   \n",
      "18          concavity2  Feature   Continuous        None        None  None   \n",
      "19     concave_points2  Feature   Continuous        None        None  None   \n",
      "20           symmetry2  Feature   Continuous        None        None  None   \n",
      "21  fractal_dimension2  Feature   Continuous        None        None  None   \n",
      "22             radius3  Feature   Continuous        None        None  None   \n",
      "23            texture3  Feature   Continuous        None        None  None   \n",
      "24          perimeter3  Feature   Continuous        None        None  None   \n",
      "25               area3  Feature   Continuous        None        None  None   \n",
      "26         smoothness3  Feature   Continuous        None        None  None   \n",
      "27        compactness3  Feature   Continuous        None        None  None   \n",
      "28          concavity3  Feature   Continuous        None        None  None   \n",
      "29     concave_points3  Feature   Continuous        None        None  None   \n",
      "30           symmetry3  Feature   Continuous        None        None  None   \n",
      "31  fractal_dimension3  Feature   Continuous        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n",
      "17             no  \n",
      "18             no  \n",
      "19             no  \n",
      "20             no  \n",
      "21             no  \n",
      "22             no  \n",
      "23             no  \n",
      "24             no  \n",
      "25             no  \n",
      "26             no  \n",
      "27             no  \n",
      "28             no  \n",
      "29             no  \n",
      "30             no  \n",
      "31             no  \n",
      "<bound method NDFrame.head of      radius1  texture1  perimeter1   area1  smoothness1  compactness1  \\\n",
      "0      17.99     10.38      122.80  1001.0      0.11840       0.27760   \n",
      "1      20.57     17.77      132.90  1326.0      0.08474       0.07864   \n",
      "2      19.69     21.25      130.00  1203.0      0.10960       0.15990   \n",
      "3      11.42     20.38       77.58   386.1      0.14250       0.28390   \n",
      "4      20.29     14.34      135.10  1297.0      0.10030       0.13280   \n",
      "..       ...       ...         ...     ...          ...           ...   \n",
      "564    21.56     22.39      142.00  1479.0      0.11100       0.11590   \n",
      "565    20.13     28.25      131.20  1261.0      0.09780       0.10340   \n",
      "566    16.60     28.08      108.30   858.1      0.08455       0.10230   \n",
      "567    20.60     29.33      140.10  1265.0      0.11780       0.27700   \n",
      "568     7.76     24.54       47.92   181.0      0.05263       0.04362   \n",
      "\n",
      "     concavity1  concave_points1  symmetry1  fractal_dimension1  ...  radius3  \\\n",
      "0       0.30010          0.14710     0.2419             0.07871  ...   25.380   \n",
      "1       0.08690          0.07017     0.1812             0.05667  ...   24.990   \n",
      "2       0.19740          0.12790     0.2069             0.05999  ...   23.570   \n",
      "3       0.24140          0.10520     0.2597             0.09744  ...   14.910   \n",
      "4       0.19800          0.10430     0.1809             0.05883  ...   22.540   \n",
      "..          ...              ...        ...                 ...  ...      ...   \n",
      "564     0.24390          0.13890     0.1726             0.05623  ...   25.450   \n",
      "565     0.14400          0.09791     0.1752             0.05533  ...   23.690   \n",
      "566     0.09251          0.05302     0.1590             0.05648  ...   18.980   \n",
      "567     0.35140          0.15200     0.2397             0.07016  ...   25.740   \n",
      "568     0.00000          0.00000     0.1587             0.05884  ...    9.456   \n",
      "\n",
      "     texture3  perimeter3   area3  smoothness3  compactness3  concavity3  \\\n",
      "0       17.33      184.60  2019.0      0.16220       0.66560      0.7119   \n",
      "1       23.41      158.80  1956.0      0.12380       0.18660      0.2416   \n",
      "2       25.53      152.50  1709.0      0.14440       0.42450      0.4504   \n",
      "3       26.50       98.87   567.7      0.20980       0.86630      0.6869   \n",
      "4       16.67      152.20  1575.0      0.13740       0.20500      0.4000   \n",
      "..        ...         ...     ...          ...           ...         ...   \n",
      "564     26.40      166.10  2027.0      0.14100       0.21130      0.4107   \n",
      "565     38.25      155.00  1731.0      0.11660       0.19220      0.3215   \n",
      "566     34.12      126.70  1124.0      0.11390       0.30940      0.3403   \n",
      "567     39.42      184.60  1821.0      0.16500       0.86810      0.9387   \n",
      "568     30.37       59.16   268.6      0.08996       0.06444      0.0000   \n",
      "\n",
      "     concave_points3  symmetry3  fractal_dimension3  \n",
      "0             0.2654     0.4601             0.11890  \n",
      "1             0.1860     0.2750             0.08902  \n",
      "2             0.2430     0.3613             0.08758  \n",
      "3             0.2575     0.6638             0.17300  \n",
      "4             0.1625     0.2364             0.07678  \n",
      "..               ...        ...                 ...  \n",
      "564           0.2216     0.2060             0.07115  \n",
      "565           0.1628     0.2572             0.06637  \n",
      "566           0.1418     0.2218             0.07820  \n",
      "567           0.2650     0.4087             0.12400  \n",
      "568           0.0000     0.2871             0.07039  \n",
      "\n",
      "[569 rows x 30 columns]>\n"
     ]
    }
   ],
   "source": [
    "## Import Wisconsin breast cancer database\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = breast_cancer_wisconsin_diagnostic.data.features\n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets\n",
    "\n",
    "# metadata\n",
    "print(breast_cancer_wisconsin_diagnostic.metadata)\n",
    "\n",
    "# variable information\n",
    "print(breast_cancer_wisconsin_diagnostic.variables)\n",
    "\n",
    "print(X.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "- Set up \"Dataset\" class to make things easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### x gives all of the features\n",
    "# X.head\n",
    "## y gives the diagnosis for each row of x\n",
    "# y.head\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    ##\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.values[:, :]\n",
    "        self.y = y\n",
    "        # ensure input data is floats\n",
    "        self.X = self.X.astype(\"float32\")\n",
    "        # label encode target and ensure the values are floats\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    "        self.y = self.y.astype(\"float32\")\n",
    "        self.y = self.y.reshape((len(self.y), 1))\n",
    "        self.X = torch.tensor(\n",
    "            X.values, dtype=torch.float32\n",
    "        )  # Convert X to PyTorch tensor\n",
    "        self.y = torch.tensor(\n",
    "            y.values, dtype=torch.float32\n",
    "        )  # Convert y to PyTorch tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    "\n",
    "    def head(self):\n",
    "        return self.X.head\n",
    "\n",
    "\n",
    "## remap y to 0, 1 -> 0 = benign, 1 = malignant\n",
    "remap_y = {\"B\": 0, \"M\": 1}\n",
    "\n",
    "y2 = y.Diagnosis.map(remap_y)\n",
    "# y2.head\n",
    "\n",
    "## create the dataset\n",
    "dat = Dataset(X, y2)\n",
    "\n",
    "\n",
    "## select train/test sets from dataset\n",
    "train_prop = 0.6  ## proportion for training set\n",
    "test_prop = 1 - train_prop\n",
    "\n",
    "## Set generator for reproducability\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "\n",
    "train, test = random_split(dat, [train_prop, test_prop], generator=generator1)\n",
    "\n",
    "train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "test_dl = DataLoader(test, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the models\n",
    "\n",
    "\n",
    "## MLP with 3 layers\n",
    "class MLP_3(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP_3, self).__init__()\n",
    "        # input to first hidden layer\n",
    "        self.hidden1 = Linear(n_inputs, 1)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity=\"relu\")\n",
    "        self.act1 = ReLU()\n",
    "        # second hidden layer\n",
    "        self.hidden2 = Linear(1, 8)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity=\"relu\")\n",
    "        self.act2 = ReLU()\n",
    "        # third hidden layer and output\n",
    "        self.hidden3 = Linear(8, 1)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        self.act3 = Sigmoid()\n",
    "\n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "        # second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # third hidden layer and output\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "## MLP 1 layer\n",
    "class MLP_1(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP_1, self).__init__()\n",
    "        # input to first hidden layer\n",
    "        self.hidden1 = Linear(n_inputs, 1)\n",
    "        kaiming_uniform_(self.hidden1.weight)\n",
    "        self.act = Sigmoid()\n",
    "\n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train the model\n",
    "## set-up\n",
    "\n",
    "\n",
    "def train_model(train_dl, model, num_epochs=1):\n",
    "    # define optimization\n",
    "    criterion = MSELoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    ## enumerate epochs\n",
    "    ## make a list to store loss data\n",
    "    loss_data = list()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            yhat = model(inputs)\n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, targets)\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    "        loss_data.append({\"Epoch\": epoch, \"Loss\": loss})\n",
    "    return pd.DataFrame(loss_data)\n",
    "\n",
    "\n",
    "def plot_learning_curve(loss_df, model_name):\n",
    "    plt.plot(loss_df[\"Epoch\"], loss_df[\"Loss\"], label=\"Training Loss\")\n",
    "    plt.title(\"Learning Curve: \", model_name)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "def evaluate_model(test_dl, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        yhat = model(inputs)\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.detach().cpu().numpy()\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        # round to class values\n",
    "        yhat = yhat.round()\n",
    "        # store\n",
    "        predictions.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    # calculate accuracy\n",
    "    # acc = accuracy_score(actuals, predictions)\n",
    "    acc = accuracy_score(actuals.flatten(), predictions.flatten())\n",
    "    return acc\n",
    "\n",
    "\n",
    "# make a class prediction for one row of data\n",
    "def predict(row, model, input_size=30):\n",
    "    assert len(row) == input_size, \"Input row size must be correct\"\n",
    "    # convert row to data\n",
    "    row = Tensor([row])\n",
    "    # make prediction\n",
    "    yhat = model(row)\n",
    "    # retrieve numpy array\n",
    "    yhat = yhat.detach().cpu().numpy()\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dvait\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\dvait\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([22])) that is different to the input size (torch.Size([22, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 1 layer: 0.379\n",
      "Accuracy for 3 layers: 0.379\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy for 3 layers: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m acc_3)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m## plot epochs vs loss\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mplot_learning_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_df_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1 layer MLP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m plot_learning_curve(loss_df_3, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3 layer MLP\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 29\u001b[0m, in \u001b[0;36mplot_learning_curve\u001b[1;34m(loss_df, model_name)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_learning_curve\u001b[39m(loss_df, model_name):\n\u001b[1;32m---> 29\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot(loss_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m], loss_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearning Curve: \u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name)\n\u001b[0;32m     31\u001b[0m     plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "## define the network\n",
    "input_size = 30\n",
    "model_1 = MLP_1(input_size)\n",
    "model_3 = MLP_3(input_size)\n",
    "num_epochs = 10\n",
    "## train it\n",
    "loss_df_1 = train_model(train_dl, model_1, num_epochs)\n",
    "loss_df_3 = train_model(train_dl, model_1, num_epochs)\n",
    "## eval\n",
    "acc_1 = evaluate_model(test_dl, model_1)\n",
    "acc_3 = evaluate_model(test_dl, model_3)\n",
    "print(\"Accuracy for 1 layer: %.3f\" % acc_1)\n",
    "print(\"Accuracy for 3 layers: %.3f\" % acc_3)\n",
    "\n",
    "## plot epochs vs loss\n",
    "plot_learning_curve(loss_df_1, \"1 layer MLP\")\n",
    "plot_learning_curve(loss_df_3, \"3 layer MLP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: Please use either ChatGPT (available through OpenAI.com) or GPT4 (available as the New Bing).  Carry out a dialogue on a topic of interest to you (technical or otherwise).  Describe your impressions (2 paragraphs are sufficient).**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
